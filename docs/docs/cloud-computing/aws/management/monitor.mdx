---
title: X-ray, Cloud Trail, AWS Config
description: Monitor
keywords:
- X-ray, Cloud Trail, AWS Config
sidebar_position: 2
---

## X-ray

These are the points for exam
- **Application Load balancers do not send data to X-Ray** - Load balancers add a trace ID to incoming HTTP requests in a header named X-Amzn-Trace-Id. Load balancers do not send data to X-Ray and do not appear as a node on your service map.

### Use X-ray to debug microservices specific issues

Imagine a company uses microservices-based infrastructure to process the API calls from clients, perform request filtering and cache requests using the AWS API Gateway. Users report receiving 501 error code and you have been contacted to find out what is failing. 

You may use X-Ray to debug the issue.

- CloudWatch can collect numbers and respond to AWS service-related events, but it can't help you debug microservices specific issues on AWS.
- X-Ray cannot be used to capture metrics and set up alarms as per the given use-case, so this option is incorrect.

The AWS X-Ray SDK needs permission to run in resources (like Lambda)

Create an IAM role with write permissions and assign it to the resources running your application. You can use AWS Identity and Access Management (IAM) to grant X-Ray permissions to users and compute resources in your account. This should be one of the first places you start by checking that your permissions are properly configured before exploring other troubleshooting options.

Here is an example of X-Ray Read-Only permissions via an IAM policy:


```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "xray:GetSamplingRules",
                "xray:GetSamplingTargets",
                "xray:GetSamplingStatisticSummaries",
                "xray:BatchGetTraces",
                "xray:GetServiceGraph",
                "xray:GetTraceGraph",
                "xray:GetTraceSummaries",
                "xray:GetGroups",
                "xray:GetGroup"
            ],
            "Resource": [
                "*"
            ]
        }
    ]
}
```


Another example of write permissions for using X-Ray via an IAM policy:


```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "xray:PutTraceSegments",
                "xray:PutTelemetryRecords",
                "xray:GetSamplingRules",
                "xray:GetSamplingTargets",
                "xray:GetSamplingStatisticSummaries"
            ],
            "Resource": [
                "*"
            ]
        }
    ]
}
```

## CloudTail

![cloudtrail-athena](/img/aws/management/monitor/cloudtrail-athena.png)

Source: [Field Notes: Analyze Cross-Account AWS KMS Call Usage with AWS CloudTrail and Amazon Athena](https://aws.amazon.com/blogs/architecture/field-notes-analyze-cross-account-aws-kms-call-usage-with-aws-cloudtrail-and-amazon-athena/)

### Organization

If you have created an organization in AWS Organizations, you can also create a trail that will log all events for all AWS accounts in that organization (**need root account permission**). This is referred to as an organization trail.

- S3 related
    - By default, CloudTrail traczks only bucket-level actions. To track object-level actions, you need to enable Amazon S3 data events 
    - A bucket owner enabled CloudTrail. It doesnâ€™t mean he can see the object access logs. The bucket owner **also needs to be object owner** to get the object access logs. Otherwise, the bucket owner **must get permissions**, through the object ACL, for the same object API to get the same object-access API logs.
- Member accounts will be **able to see the organization trail**, but cannot modify or delete it. (By default, member accounts will not have access to the log files for the organization trail in the Amazon S3 bucket.)
- Organization trails must be created in the master account, and when specified as applying to an organization, are automatically applied to all member accounts in the organization.

### Events

- **Management Events**: These events track management operations performed on AWS resources, such as creating, modifying, or deleting resources. Examples include EC2 instance launches, S3 bucket creations, IAM policy updates, etc.
- **Data Events**: These events capture data-related operations performed on AWS resources. Examples include S3 object access, AWS Lambda function invocations, and Amazon RDS database queries.
- **CloudTrail Insights Events**: CloudTrail Insights helps identify unusual or potentially harmful activity in your AWS account. It generates events for specific patterns identified as potentially high-risk actions.

### Log file integrity validation(digest file)

> TL;DR - Log file integrity validation is for auditing integrity of the CloudTrail log files by using digest file

:::infoTips
You can use Amazon S3 MFA Delete on the S3 bucket that holds CloudTrail logs and digest files to secure the CloudTrail logs
:::

When you enable log file integrity validation, CloudTrail creates a hash for every log file that it delivers. Every hour, CloudTrail also **creates and delivers a file that references the log files for the last hour and contains a hash of each**. This file is called a digest file. CloudTrail signs each digest file using the private key of a public and private key pair. After delivery, you can use the public key to validate the digest file. CloudTrail uses different key pairs for each AWS region.

These digest files are stored in the same Amazon S3 bucket as the log files but in a separate folder. This separation allows for granular security policies and ensures compatibility with existing log processing solutions. Each digest file also includes the digital signature of the previous digest file (if available) in its metadata properties.

![file-integrity-validation](/img/aws/management/monitor/file-integrity-validation.jpg)
Source: [CloudTrail log file Integrity Validation](https://www.youtube.com/watch?v=rk0RHxQCD8Q)

The image above illustrate - if we trust the latest digest file that we have, we can identify if any of the digests are missing or invalid, and this gives us a chain of digest file trust. If we trust the latest, then we trust them all.


### Notes

- CloudTrail can deliver log files **from multiple regions to a single Amazon S3 bucket**. As long as CloudTrail has permissions to write to an S3 bucket, **the bucket for a multi-Region trail does not have to be in the trail's home Region**.
    - You can configure CloudTrail to deliver log files from multiple Regions to a single S3 bucket for a single account. For example, you have a trail in the US West (Oregon) Region that is configured to deliver log files to a S3 bucket, and a CloudWatch Logs log group. When you change an existing single-Region trail to log all Regions, CloudTrail logs events from all Regions that are in a single AWS partition in your account. CloudTrail delivers log files to the same S3 bucket and CloudWatch Logs log group.  ref: [Receiving CloudTrail log files from multiple Regions](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/receive-cloudtrail-log-files-from-multiple-regions.html)
- **Digest files** can only be encrypted with Amazon S3-managed encryption keys (SSE-S3).
- **Log files** is encrypted by **SSE-S3** by default but you can change it to use **SSE-KMS**.


## AWS Config

![config1](/img/aws/management/monitor/config1.png)
![config2](/img/aws/management/monitor/config2.png)

AWS Config is a service that tracks and evaluates the configuration and compliance of AWS resources. It uses configurable rules to assess resources against desired settings, such as logging for S3 buckets or MFA for IAM users. 

AWS Lambda functions perform compliance evaluations, and **auto-remediation can automatically correct non-compliant resources**. 

### Notification

AWS Config sends notifications for the following events:
- Configuration item change for a resource.
- Configuration history for a resource was delivered for your account.
- Configuration snapshot for recorded resources was started and delivered for your account.
- Compliance state of your resources and whether they are compliant with your rules.
- Evaluation started for a rule against your resources.
- AWS Config failed to deliver the notification to your account.

### Triggers

![specifying_triggers_for_aws_config_rules](/img/aws/management/monitor/specifying_triggers_for_aws_config_rules.jpg)

When you add a rule to your account, you can specify when you want AWS Config to run the rule; this is called a trigger. AWS Config evaluates your resource configurations against the rule when the trigger occurs. There are two types of triggers:

- **Configuration changes**: AWS Config runs evaluations for the rule when certain types of resources are created, changed, or deleted.
- **Periodic**: AWS Config runs evaluations for the rule at a frequency that you choose (for example, every 24 hours).

:::infoYou can use both types in one rule
If you choose **both configuration changes and periodic to the same rule**, AWS Config invokes your Lambda function when it detects a configuration change and also at the frequency that you specify. 
:::

### Some practices

- AWS Config includes **auto-remediation** for specific non-compliant S3 activities through rules like `s3-bucket-logging-enabled` and `s3-bucket-server-side-encryption-enabled`.
- Use EventBridge to detect NON_COMPLIANT in AWS Config and send message via SNS
    - You can use an EventBridge rule with a custom event pattern and an input transformer to match an AWS Config evaluation rule output as `NON_COMPLIANT`. Then, route the response to an Amazon Simple Notification Service (Amazon SNS) topic.
- AWS Config sends notifications **only when the compliance status changes**.  If a resource was previously non-compliant and is still non-compliant, Config will not send a new notification.
- AWS config rule, `require-tags` is for checking if a resource contains the tags that you specify.